{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 411362/411363: 100%|██████████| 411363/411363 [05:47<00:00, 1184.55it/s]\n"
     ]
    }
   ],
   "source": [
    "'''处理学姐给的resultxxxx.json数据'''\n",
    "\n",
    "import os, json, re, hashlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_province(affiliations):\n",
    "    provinces = [\"河北\",\"山西\",\"黑龙江\",\"吉林\",\"辽宁\",\"江苏\",\"浙江\",\"安徽\",\"福建\",\"江西\",\"山东\",\"河南\",\"湖北\",\"湖南\",\"广东\",\"海南\",\"四川\",\"贵州\",\"云南\",\"陕西\",\"甘肃\",\"青海\",\"台湾\",\"内蒙古\",\"广西\",\"西藏\",\"宁夏\",\"新疆\",\"北京\",\"天津\",\"上海\",\"重庆\",\"香港\",\"澳门\"]\n",
    "\n",
    "    cities = {\n",
    "        \"北京\":[\n",
    "            \"北京\"\n",
    "        ],\n",
    "        \"上海\":[\n",
    "            \"上海\"\n",
    "        ],\n",
    "        \"重庆\":[\n",
    "            \"重庆\",\"西南政法大学\"\n",
    "        ],\n",
    "        \"天津\":[\n",
    "            \"天津\"\n",
    "        ],\n",
    "        \"河北\":[\n",
    "            \"河北\",\"石家庄\",\"唐山\",\"秦皇岛\",\"邯郸\",\"邢台\",\"保定\",\"张家口\",\"承德\",\"沧州\",\"廊坊\",\"衡水\"\n",
    "        ],\n",
    "        \"山西\":[\n",
    "            \"山西\",\"太原\",\"大同\",\"阳泉\",\"长治\",\"晋城\",\"朔州\",\"晋中\",\"运城\",\"忻州\",\"临汾\",\"吕梁\"\n",
    "        ],\n",
    "        \"内蒙古\":[\n",
    "            \"内蒙古\",\"呼和浩特\",\"包头\",\"乌海\",\"赤峰\",\"通辽\",\"鄂尔多斯\",\"呼伦贝尔\",\"巴彦淖尔\",\"乌兰察布\",\"兴安盟\",\"锡林郭勒盟\",\"伊克昭盟\",\"阿拉善\"\n",
    "        ],\n",
    "        \"辽宁\":[\n",
    "            \"辽宁\",\"沈阳\",\"大连\",\"鞍山\",\"抚顺\",\"本溪\",\"丹东\",\"锦州\",\"营口\",\"阜新\",\"辽阳\",\"盘锦\",\"铁岭\",\"朝阳\",\"葫芦岛\"\n",
    "        ],\n",
    "        \"吉林\":[\n",
    "            \"吉林\",\"长春\",\"吉林\",\"四平\",\"辽源\",\"通化\",\"白山\",\"松原\",\"白城\",\"延边\"\n",
    "        ],\n",
    "        \"黑龙江\":[\n",
    "            \"黑龙江\",\"哈尔滨\",\"齐齐哈尔\",\"鸡西\",\"鹤岗\",\"双鸭山\",\"大庆\",\"伊春\",\"佳木斯\",\"七台河\",\"牡丹江\",\"黑河\",\"绥化\",\"大兴安岭\"\n",
    "        ],\n",
    "        \"江苏\":[\n",
    "            \"江苏\",\"南京\",\"无锡\",\"徐州\",\"常州\",\"苏州\",\"南通\",\"连云港\",\"淮安\",\"盐城\",\"扬州\",\"镇江\",\"泰州\",\"宿迁\",\"淮阴\"\n",
    "        ],\n",
    "        \"浙江\":[\n",
    "            \"浙江\",\"杭州\",\"宁波\",\"温州\",\"嘉兴\",\"湖州\",\"绍兴\",\"金华\",\"衢州\",\"舟山\",\"台州\",\"丽水\"\n",
    "        ],\n",
    "        \"安徽\":[\n",
    "            \"安徽\",\"合肥\",\"芜湖\",\"蚌埠\",\"淮南\",\"马鞍山\",\"淮北\",\"铜陵\",\"安庆\",\"黄山\",\"阜阳\",\"宿州\",\"滁州\",\"六安\",\"宣城\",\"池州\",\"亳州\"\n",
    "        ],\n",
    "        \"福建\":[\n",
    "            \"福建\",\"福州\",\"厦门\",\"莆田\",\"三明\",\"泉州\",\"漳州\",\"南平\",\"龙岩\",\"宁德\"\n",
    "        ],\n",
    "        \"江西\":[\n",
    "            \"江西\",\"南昌\",\"景德镇\",\"萍乡\",\"九江\",\"抚州\",\"鹰潭\",\"赣州\",\"吉安\",\"宜春\",\"新余\",\"上饶\",\"赣南\"\n",
    "        ],\n",
    "        \"山东\":[\n",
    "            \"山东\",\"济南\",\"青岛\",\"淄博\",\"枣庄\",\"东营\",\"烟台\",\"潍坊\",\"济宁\",\"泰安\",\"威海\",\"日照\",\"临沂\",\"德州\",\"聊城\",\"滨州\",\"菏泽\"\n",
    "        ],\n",
    "        \"河南\":[\n",
    "            \"河南\",\"郑州\",\"开封\",\"洛阳\",\"平顶山\",\"安阳\",\"鹤壁\",\"新乡\",\"焦作\",\"濮阳\",\"许昌\",\"漯河\",\"三门峡\",\"南阳\",\"商丘\",\"信阳\",\"周口\",\"驻马店\",\"济源\"\n",
    "        ],\n",
    "        \"湖北\":[\n",
    "            \"湖北\",\"武汉\",\"黄石\",\"十堰\",\"宜昌\",\"襄阳\",\"鄂州\",\"荆门\",\"孝感\",\"荆州\",\"黄冈\",\"咸宁\",\"随州\",\"恩施\",\"仙桃\",\"潜江\",\"天门\",\"神农架\"\n",
    "        ],\n",
    "        \"湖南\":[\n",
    "            \"湖南\",\"长沙\",\"株洲\",\"湘潭\",\"衡阳\",\"邵阳\",\"岳阳\",\"常德\",\"张家界\",\"益阳\",\"郴州\",\"永州\",\"怀化\",\"娄底\",\"湘西\"\n",
    "        ],\n",
    "        \"广东\":[\n",
    "            \"广东\",\"广州\",\"韶关\",\"深圳\",\"珠海\",\"汕头\",\"佛山\",\"江门\",\"湛江\",\"茂名\",\"肇庆\",\"惠州\",\"梅州\",\"汕尾\",\"河源\",\"阳江\",\"清远\",\"东莞\",\"中山\",\"潮州\",\"揭阳\",\"云浮\"\n",
    "        ],\n",
    "        \"广西\":[\n",
    "            \"广西\",\"南宁\",\"柳州\",\"桂林\",\"梧州\",\"北海\",\"防城港\",\"钦州\",\"贵港\",\"玉林\",\"百色\",\"贺州\",\"河池\",\"来宾\",\"崇左\"\n",
    "        ],\n",
    "        \"海南\":[\n",
    "            \"海南\",\"海口\",\"三亚\",\"三沙\",\"儋州\",\"琼海\",\"五指山\",\"文昌\",\"万宁\",\"东方\",\"定安\",\"屯昌\",\"澄迈\",\"临高\",\"白沙\",\"昌江\",\"乐东\",\"陵水\",\"保亭\",\"琼中\"\n",
    "        ],\n",
    "        \"四川\":[\n",
    "            \"四川\",\"成都\",\"自贡\",\"攀枝花\",\"泸州\",\"德阳\",\"绵阳\",\"广元\",\"遂宁\",\"内江\",\"乐山\",\"南充\",\"眉山\",\"宜宾\",\"广安\",\"达州\",\"雅安\",\"巴中\",\"资阳\",\"阿坝\",\"甘孜\",\"凉山\",\"巴中\",\"眉山\",\"资阳\"\n",
    "        ],\n",
    "        \"贵州\":[\n",
    "            \"贵州\",\"贵阳\",\"六盘水\",\"遵义\",\"安顺\",\"毕节\",\"铜仁\",\"黔西南\",\"黔东南\",\"安顺\"\n",
    "        ],\n",
    "        \"云南\":[\n",
    "            \"云南\",\"昆明\",\"曲靖\",\"玉溪\",\"保山\",\"昭通\",\"丽江\",\"普洱\",\"临沧\",\"楚雄\",\"红河哈尼\",\"文山\",\"思茅\",\"西双版纳\",\"大理\",\"德宏\",\"怒江\"\n",
    "        ],\n",
    "        \"西藏\":[\n",
    "            \"西藏\",\"拉萨\",\"日喀则\",\"昌都\",\"林芝\",\"山南\",\"那曲\",\"阿里\"\n",
    "        ],\n",
    "        \"陕西\":[\n",
    "            \"陕西\",\"西安\",\"铜川\",\"宝鸡\",\"咸阳\",\"渭南\",\"延安\",\"汉中\",\"榆林\",\"安康\",\"商洛\"\n",
    "        ],\n",
    "        \"甘肃\":[\n",
    "            \"甘肃\",\"兰州\",\"嘉峪关\",\"金昌\",\"白银\",\"天水\",\"武威\",\"张掖\",\"平凉\",\"酒泉\",\"庆阳\",\"定西\",\"陇南\",\"临夏\",\"甘南\"\n",
    "        ],\n",
    "        \"青海\":[\n",
    "            \"青海\",\"西宁\",\"海东\",\"玉树\",\"果洛\",\"黄南\",\"海西\",\"海北\",\"海南藏族\"\n",
    "        ],\n",
    "        \"宁夏\":[\n",
    "            \"宁夏\",\"银川\",\"石嘴山\",\"吴忠\",\"固原\",\"中卫\"\n",
    "        ],\n",
    "        \"新疆\":[\n",
    "            \"新疆\",\"乌鲁木齐\",\"克拉玛依\",\"吐鲁番\",\"哈密\",\"昌吉\",\"博尔塔\",\"巴音郭楞\",\"阿克苏\",\"克孜勒苏柯尔克孜\",\"喀什\",\"和田\",\"伊犁\",\"塔城\",\"阿勒泰\",\"石河子\",\"阿拉尔\",\"图木舒克\",\"五家渠\"\n",
    "        ],\n",
    "        \"台湾\":[\n",
    "            \"台湾\",\"台北\",\"高雄\",\"基隆\",\"台中\",\"台南\",\"新北\",\"桃源\",\"宜兰\",\"新竹\",\"嘉义\"\n",
    "        ],\n",
    "        \"香港\":[\n",
    "            \"香港\"\n",
    "        ],\n",
    "        \"澳门\":[\n",
    "            \"澳门\"\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    paper_province = []\n",
    "    for province in provinces:\n",
    "        for city in cities[province]:\n",
    "            if re.search(city, affiliations)!=None:\n",
    "                paper_province.append(province)\n",
    "                break\n",
    "    return paper_province\n",
    "\n",
    "def preprocess(entry):  # 将作者和单位转换为列表，有数字出现的打上标签authors[] affiliations[] tags[]\n",
    "    entry['tags']=[]\n",
    "\n",
    "    # 检查所有条目是否全面\n",
    "    for value in entry.values():\n",
    "        if value==\"none\" or value=='':\n",
    "            entry['tags'].append(\"incomplete\")\n",
    "\n",
    "    # 处理作者\n",
    "    delimiter_pattern=re.compile(r'[，；; \\t\\s]')\n",
    "    authors = entry.get('authors')\n",
    "    delimiters_author = delimiter_pattern.search(authors)\n",
    "    # commas_authors=re.search(r'，',authors)\n",
    "    # semicolons_authors=re.search(r'；',authors)\n",
    "    numbers = re.findall(r'\\d', authors)\n",
    "    if numbers:  # 有数字\n",
    "        entry['tags'].append('with nums')\n",
    "    if authors==\"none\" or authors=='':\n",
    "        entry['authors']=[]\n",
    "        entry['tags'].append(\"authors missing\")\n",
    "    elif delimiters_author:\n",
    "        entry['authors']=re.split(delimiter_pattern,authors)\n",
    "    else:  # 只有一个作者\n",
    "        entry['authors']=[authors]\n",
    "\n",
    "    # 处理省份\n",
    "    if type(entry['province'])!=list:\n",
    "        province_list = []\n",
    "        province_list = get_province(entry.get('affiliations'))\n",
    "        if entry['province'] not in province_list:\n",
    "            province_list.append(entry['province'])\n",
    "        entry['province'] = province_list\n",
    "\n",
    "    delimiter_pattern=re.compile(r'[,，；; \\t\\s]')\n",
    "    # 处理单位\n",
    "    affiliations = entry.get('affiliations')\n",
    "    delimiters_affiliation = delimiter_pattern.search(affiliations)\n",
    "    if affiliations==\"none\" or affiliations=='':\n",
    "        entry['affiliations']=[]\n",
    "        entry['tags'].append(\"keywords missing\")\n",
    "    elif delimiters_affiliation:\n",
    "        entry['affiliations']=re.split(delimiter_pattern,affiliations)\n",
    "    else:  # 只有一个单位\n",
    "        entry['affiliations'] = [affiliations]\n",
    "\n",
    "    # 处理关键词\n",
    "    keywords = entry.get('keywords')\n",
    "    keywords.strip()\n",
    "    delimiters_affiliation = delimiter_pattern.search(keywords)\n",
    "    if keywords==\"none\" or keywords=='':\n",
    "        entry['keywords']=[]\n",
    "        entry['tags'].append(\"keywords missing\")\n",
    "    elif delimiters_affiliation:\n",
    "        tmp_keywords = re.split(delimiter_pattern,keywords)\n",
    "        entry['keywords']=[]\n",
    "        for tmp_keyword in tmp_keywords:\n",
    "            if tmp_keyword!='':\n",
    "                entry['keywords'].append(tmp_keyword)\n",
    "    else:  # 只有一个单位\n",
    "        entry['keywords'] = [keywords]\n",
    "\n",
    "    # 处理引用\n",
    "    citation = entry.get('citation')\n",
    "    if type(citation)==str:\n",
    "        citation.strip()\n",
    "        try:\n",
    "            citation = int(citation)\n",
    "        except:\n",
    "            entry['tags'].append(\"citation error\")\n",
    "    entry['citation'] = citation\n",
    "\n",
    "    # 处理年份\n",
    "    year = entry.get('year')\n",
    "    if type(year)==str:\n",
    "        year.strip()\n",
    "        try:\n",
    "            year = int(year)\n",
    "        except:\n",
    "            entry['tags'].append(\"year error\")\n",
    "    entry['year'] = year\n",
    "\n",
    "    # 生成UID\n",
    "    metadata_str=f\"{entry['title']}{entry['source']}\"\n",
    "    # 将中文字符转换为字节序列（UTF-8 编码）\n",
    "    metadata_bytes=metadata_str.encode('utf-8')\n",
    "    uid=hashlib.sha256(metadata_bytes).hexdigest()\n",
    "    entry['uid']=uid\n",
    "\n",
    "    return entry\n",
    "\n",
    "result_json_path = r\"D:\\vscode_workspace\\ZhongYiPapers\\database\\分省份数据\"\n",
    "final_json_save_path = r\"D:\\vscode_workspace\\ZhongYiPapers\\database\\final\\tmp.json\"\n",
    "filenames = os.listdir(result_json_path)\n",
    "result_json_list = []\n",
    "for filename in filenames:\n",
    "    with open(result_json_path+r\"/\"+filename, 'r', encoding='utf-8') as f:\n",
    "        items_json_list = json.load(f)\n",
    "        result_json_list.extend(items_json_list)\n",
    "total_num = len(result_json_list)\n",
    "# total_num = 10\n",
    "pbar = tqdm(range(total_num))\n",
    "final_item_dict = {}\n",
    "for item_index in pbar:\n",
    "    if 'title' not in result_json_list[item_index]:\n",
    "        continue\n",
    "    tmp = {}\n",
    "    pbar.set_description(\"Processing %s\" % item_index + \"/%s\"%total_num) # 设置描述\n",
    "    tmp = preprocess(result_json_list[item_index])\n",
    "    final_item_dict[tmp['uid']] = tmp\n",
    "\n",
    "# utf-8将一个汉字编码为3个字节,gbk将一个汉字编码为2个字节,\n",
    "with open(final_json_save_path, 'w', encoding='utf-8') as new_f:  # 重新写入\n",
    "    json.dump(final_item_dict, new_f, ensure_ascii=False, indent=4) # 最后一个参数会保证dump之后的结果所有的字符都能被ascii表示\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 18857/18858: 100%|██████████| 18858/18858 [00:09<00:00, 2067.24it/s]\n"
     ]
    }
   ],
   "source": [
    "'''处理学姐给的resultxxxx.json数据'''\n",
    "\n",
    "import os, json, re, hashlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess(entry):  # 将作者和单位转换为列表，有数字出现的打上标签authors[] affiliations[] tags[]\n",
    "    entry['tags']=[]\n",
    "\n",
    "    # 检查所有条目是否全面\n",
    "    for value in entry.values():\n",
    "        if value==\"none\" or value=='':\n",
    "            entry['tags'].append(\"incomplete\")\n",
    "\n",
    "    # 处理作者\n",
    "    delimiter_pattern=re.compile(r'[，；; \\t\\s]')\n",
    "    authors = entry.get('authors')\n",
    "    delimiters_author = delimiter_pattern.search(authors)\n",
    "    # commas_authors=re.search(r'，',authors)\n",
    "    # semicolons_authors=re.search(r'；',authors)\n",
    "    numbers = re.findall(r'\\d', authors)\n",
    "    if numbers:  # 有数字\n",
    "        entry['tags'].append('with nums')\n",
    "    if authors==\"none\" or authors=='':\n",
    "        entry['authors']=[]\n",
    "        entry['tags'].append(\"authors missing\")\n",
    "    elif delimiters_author:\n",
    "        entry['authors']=re.split(delimiter_pattern,authors)\n",
    "    else:  # 只有一个作者\n",
    "        entry['authors']=[authors]\n",
    "\n",
    "    delimiter_pattern=re.compile(r'[,，；; \\t\\s]')\n",
    "    # 处理单位\n",
    "    affiliations = entry.get('affiliations')\n",
    "    delimiters_affiliation = delimiter_pattern.search(affiliations)\n",
    "    if affiliations==\"none\" or affiliations=='':\n",
    "        entry['affiliations']=[]\n",
    "        entry['tags'].append(\"keywords missing\")\n",
    "    elif delimiters_affiliation:\n",
    "        entry['affiliations']=re.split(delimiter_pattern,affiliations)\n",
    "    else:  # 只有一个单位\n",
    "        entry['affiliations'] = [affiliations]\n",
    "\n",
    "    # 处理关键词\n",
    "    keywords = entry.get('keywords')\n",
    "    keywords.strip()\n",
    "    delimiters_affiliation = delimiter_pattern.search(keywords)\n",
    "    if keywords==\"none\" or keywords=='':\n",
    "        entry['keywords']=[]\n",
    "        entry['tags'].append(\"keywords missing\")\n",
    "    elif delimiters_affiliation:\n",
    "        tmp_keywords = re.split(delimiter_pattern,keywords)\n",
    "        entry['keywords']=[]\n",
    "        for tmp_keyword in tmp_keywords:\n",
    "            if tmp_keyword!='':\n",
    "                entry['keywords'].append(tmp_keyword)\n",
    "    else:  # 只有一个单位\n",
    "        entry['keywords'] = [keywords]\n",
    "\n",
    "    # 处理省份\n",
    "    if type(entry['province'])!=list:\n",
    "        entry['province'] = [entry['province']]\n",
    "\n",
    "    # 处理引用\n",
    "    citation = entry.get('citation')\n",
    "    if type(citation)==str:\n",
    "        citation.strip()\n",
    "        try:\n",
    "            citation = int(citation)\n",
    "        except:\n",
    "            entry['tags'].append(\"citation error\")\n",
    "    entry['citation'] = citation\n",
    "\n",
    "    # 处理年份\n",
    "    year = entry.get('year')\n",
    "    if type(year)==str:\n",
    "        year.strip()\n",
    "        try:\n",
    "            year = int(year)\n",
    "        except:\n",
    "            entry['tags'].append(\"year error\")\n",
    "    entry['year'] = year\n",
    "\n",
    "    # 生成UID\n",
    "    metadata_str=f\"{entry['title']}{entry['source']}\"\n",
    "    # 将中文字符转换为字节序列（UTF-8 编码）\n",
    "    metadata_bytes=metadata_str.encode('utf-8')\n",
    "    uid=hashlib.sha256(metadata_bytes).hexdigest()\n",
    "    entry['uid']=uid\n",
    "\n",
    "    return entry\n",
    "\n",
    "result_json_path = r\"D:\\vscode_workspace\\ZhongYiPapers\\database\\lzd数据\\papers_unnumed_authers.json\"\n",
    "final_json_save_path = r\"D:\\vscode_workspace\\ZhongYiPapers\\database\\final\\tmp.json\"\n",
    "result_json_list = []\n",
    "with open(result_json_path, encoding='utf-8') as f:\n",
    "    result_json_list = json.load(f)\n",
    "total_num = len(result_json_list)\n",
    "# total_num = 10\n",
    "pbar = tqdm(range(total_num))\n",
    "final_item_dict = {}\n",
    "for item_index in pbar:\n",
    "    if 'title' not in result_json_list[item_index]:\n",
    "        continue\n",
    "    tmp = {}\n",
    "    pbar.set_description(\"Processing %s\" % item_index + \"/%s\"%total_num) # 设置描述\n",
    "    tmp = preprocess(result_json_list[item_index])\n",
    "    final_item_dict[tmp['uid']] = tmp\n",
    "\n",
    "# utf-8将一个汉字编码为3个字节,gbk将一个汉字编码为2个字节,\n",
    "with open(final_json_save_path, 'w', encoding='utf-8') as new_f:  # 重新写入\n",
    "    json.dump(final_item_dict, new_f, ensure_ascii=False, indent=4) # 最后一个参数会保证dump之后的结果所有的字符都能被ascii表示\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\vscode_workspace\\ZhongYiPapers\\database\\final\\lzd_numed.json\", encoding='utf-8') as f:\n",
    "    lzd_numed = json.load(f)\n",
    "    lzd_numed_keys = list(lzd_numed.keys())\n",
    "with open(r\"D:\\vscode_workspace\\ZhongYiPapers\\database\\final\\lzd_unnumed.json\", encoding='utf-8') as f:\n",
    "    lzd_unnumed = json.load(f)\n",
    "    lzd_unnumed_keys = list(lzd_unnumed.keys())\n",
    "with open(r\"D:\\vscode_workspace\\ZhongYiPapers\\database\\final\\tmp.json\", encoding='utf-8') as f:\n",
    "    fby = json.load(f)\n",
    "    fby_keys = list(fby.keys())\n",
    "\n",
    "final_uids = []\n",
    "final_jsons_dict = {}\n",
    "\n",
    "for lzd_numed_key in lzd_numed_keys:\n",
    "    final_uids.append(lzd_numed_key)\n",
    "    tmp = {}\n",
    "    tmp = lzd_numed[lzd_numed_key]\n",
    "    tmp['tags'].append('lzd')\n",
    "    final_jsons_dict[lzd_numed_key] = tmp\n",
    "\n",
    "for lzd_unnumed_key in lzd_unnumed_keys:\n",
    "    final_uids.append(lzd_unnumed_key)\n",
    "    tmp = {}\n",
    "    tmp = lzd_unnumed[lzd_unnumed_key]\n",
    "    tmp['tags'].append('lzd')\n",
    "    final_jsons_dict[lzd_unnumed_key] = tmp\n",
    "\n",
    "for fby_key in fby_keys:\n",
    "    final_uids.append(fby_key)\n",
    "    tmp = {}\n",
    "    tmp = fby[fby_key]\n",
    "    tmp['tags'].append('fby')\n",
    "    final_jsons_dict[fby_key] = tmp\n",
    "\n",
    "final_uids.sort()\n",
    "final = [final_uids, final_jsons_dict]\n",
    "\n",
    "with open(r\"D:\\vscode_workspace\\ZhongYiPapers\\database\\final\\final.json\", 'w', encoding='utf-8') as new_f:  # 重新写入\n",
    "    json.dump(final, new_f, ensure_ascii=False, indent=4) # 最后一个参数会保证dump之后的结果所有的字符都能被ascii表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tags': [777, 666]}, [123, 456]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\n",
    "    \"tags\":[777]\n",
    "}\n",
    "b = {}\n",
    "b = a\n",
    "tmp_tag = b.get('tags')\n",
    "b['tags'].append(666)\n",
    "b = [123,456]\n",
    "c = [a, b]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1sad5a6sf', '7as8', 'asdf87as98s8d', 'sdaf48dx9q']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\"1sad5a6sf\", \"asdf87as98s8d\", \"7as8\", \"sdaf48dx9q\"]\n",
    "a.sort()\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
